from flask import Flask, render_template, request, redirect, url_for
import os
import pandas as pd
import joblib
from werkzeug.utils import secure_filename
import psutil
import pyshark
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import winreg
import winshell


UPLOAD_FOLDER = "uploads"
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

app = Flask(__name__)
iso_forest_model = joblib.load('isolation_forest_model.pkl')
VICTIM_FILE = None
LOGS = {'CSV Analysis': [], 'Windows Artifacts': {}, 'Other Analysis': []}




def fetch_windows_artifacts():
    global LOGS
    try:
        if 'Windows Artifacts' not in LOGS:
            LOGS['Windows Artifacts'] = {}  # Initialize as a dictionary

        # Fetch running processes
        LOGS['Windows Artifacts']['pid_processes'].append(fetch_running_processes())

        # Fetch registry entries
        LOGS['Windows Artifacts']['registry_entries'].append( fetch_registry_entries())

        # Fetch network connections
        LOGS['Windows Artifacts']['network_connections'].append( fetch_network_connections())

        # Fetch recycle bin entries
        LOGS['Windows Artifacts']['recycle_bin_entries'].append(fetch_recycle_bin_entries())
    except Exception as e:
        # Append error message to the appropriate key in Other Analysis
        LOGS['Other Analysis'].append("Error fetching Windows artifacts: {}".format(str(e)))



@app.route('/artifacts')
def display_artifacts():
    try:
        global LOGS
        
        # Clear previous logs
        LOGS['Windows Artifacts'] = {'pid_processes': [], 'registry_entries': [], 'network_connections': [], 'recycle_bin_entries': []}
        LOGS['Other Analysis'] = []
        
        # Fetch Windows artifacts
        fetch_windows_artifacts()
        
        # Monitor behavior and analyze data
        monitor_behavior()
        analysis_result = analyze_data()
        
        # If analysis result is available, proceed
        if analysis_result:
            # Calculate file size
            file_size = os.path.getsize(VICTIM_FILE)
            analysis_result['file_size'] = file_size
            
            # Update logs with fetched artifacts
            LOGS['Windows Artifacts']["network_connections"] = fetch_network_connections()
            LOGS['Windows Artifacts']["recycle_bin_entries"] = fetch_recycle_bin_entries()
            LOGS['Windows Artifacts']["registry_entries"] = fetch_registry_entries()
            
            # Debug: Print the contents of LOGS['Windows Artifacts']
            print("Windows Artifacts pid_processes Data:", len(LOGS['Windows Artifacts']["pid_processes"]), type(LOGS['Windows Artifacts']["pid_processes"]))
            print("Windows Artifacts registry_entries Data:", len(LOGS['Windows Artifacts']["registry_entries"]), type(LOGS['Windows Artifacts']["registry_entries"]), LOGS['Windows Artifacts']["registry_entries"])
            print("Windows Artifacts network_connections Data:", len(LOGS['Windows Artifacts']["network_connections"]), type(LOGS['Windows Artifacts']["network_connections"]))
            print("Windows Artifacts recycle_bin_entries Data:", len(LOGS['Windows Artifacts']["recycle_bin_entries"]), type(LOGS['Windows Artifacts']["recycle_bin_entries"]), LOGS['Windows Artifacts']["recycle_bin_entries"])
            print("LOGS['Windows Artifacts']:", LOGS['Windows Artifacts'])
            
            # Pass logs to the template for rendering
            return render_template('artifacts.html', artefact_logs=LOGS['Windows Artifacts'], other_logs=LOGS['Other Analysis'])
        
        # If there is no analysis result, return a default response
        return render_template('error.html', error="Error occurred during analysis.")
    
    # Catch any exceptions and handle them appropriately
    except Exception as e:
        error_message = str(e)
        LOGS['Windows Artifacts'].append("Error occurred during fetching: {}".format(error_message))
        return render_template('error.html', error=error_message)
    
def fetch_registry_entries():
    try:
        entries = []

        # Fetch registry entries using winreg
        with winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE) as hkey:
            with winreg.OpenKey(hkey, r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run") as key:
                num_values = winreg.QueryInfoKey(key)[1]
                for i in range(num_values):
                    name, value, _ = winreg.EnumValue(key, i)
                    entries.append({'name': name, 'value': value})

        return entries
    except Exception as e:
        print("Error:", e)
        return []


def fetch_running_processes():
    global LOGS
    try:
        # Fetch running processes
        LOGS['Windows Artifacts']['pid_processes'].append("Fetching running processes...")
        processes = []
        for proc in psutil.process_iter(['pid', 'name']):
            processes.append({"PID": proc.info['pid'], "Name": proc.info['name']})
        LOGS['Windows Artifacts']['pid_processes'].extend(processes)
        return processes
    except Exception as e:
        LOGS['Windows Artifacts']['pid_processes'].append("Error fetching running processes: {}".format(str(e)))
        return []
    

def fetch_network_connections():
    global LOGS
    try:
        connections = []
        # Fetch network connections
        for conn in psutil.net_connections(kind='inet'):
            connections.append({
                'local_address': conn.laddr,
                'remote_address': conn.raddr,
                'status': conn.status
            })
        LOGS['Windows Artifacts']["network_connections"] = connections 
        return connections
    except Exception as e:
        LOGS['Windows Artifacts'].append("Error fetching network connections: {}".format(str(e)))


def fetch_recycle_bin_entries():
    try:
        recycle_bin_entries = []
        # Get recycle bin items using winshell
        recycle_bin = winshell.recycle_bin()
        # Iterate over recycle bin items
        for item in recycle_bin:
            recycle_bin_entries.append(item.original_filename())
        return recycle_bin_entries
    except Exception as e:
        print("Error:", e)
        return []


class FileSystemMonitor(FileSystemEventHandler):
    def on_created(self, event):
        LOGS['Other Analysis'].append(f"File created: {event.src_path}")

    def on_modified(self, event):
        LOGS['Other Analysis'].append(f"File modified: {event.src_path}")

    def on_deleted(self, event):
        LOGS['Other Analysis'].append(f"File deleted: {event.src_path}")


def monitor_behavior():
    global LOGS
    try:
        # Monitor file system operations
        LOGS['Other Analysis'].append("Monitoring file system operations...")
        observer = Observer()
        observer.schedule(FileSystemMonitor(), path='.')
        observer.start()

        # Monitor network activity
        LOGS['Other Analysis'].append("Monitoring network activity...")
        cap = pyshark.LiveCapture(interface='eth0')
        cap.sniff(timeout=10)
        for pkt in cap:
            LOGS['Other Analysis'].append(f"Network packet: {pkt}")

        # Monitor process creation
        LOGS['Other Analysis'].append("Monitoring process creation...")
        for proc in psutil.process_iter(['pid', 'name']):
            LOGS['Other Analysis'].append(f"Process created: {proc.info}")

        observer.join()

    except Exception as e:
        LOGS['Other Analysis'].append("Error monitoring behavior: {}".format(str(e)))


def analyze_data():
    global LOGS
    try:
        # Load data from the uploaded file
        df = pd.read_csv(VICTIM_FILE)
        LOGS['CSV Analysis'].append("File loaded successfully: {}".format(os.path.basename(VICTIM_FILE)))
        # Remove non-informative columns
        df.drop(columns=['hash'], inplace=True)
        LOGS['CSV Analysis'].append("Non-informative columns removed")

        # Check if there are any records with classification 0
        if (df['classification'] == 0).any():
            LOGS['CSV Analysis'].append("Not healthy records found in the dataset.")
            not_healthy_count = (df['classification'] == 0).sum()
            healthy_count = len(df) - not_healthy_count
        else:
            LOGS['CSV Analysis'].append("All records are healthy.")
            healthy_count = len(df)
            not_healthy_count = 0
        
        LOGS['CSV Analysis'].append("Analysis successful. Healthy Count: {}, Not Healthy Count: {}".format(healthy_count, not_healthy_count))
        analysis_result = {
            'filename': os.path.basename(VICTIM_FILE),
            'healthy_count': healthy_count,
            'not_healthy_count': not_healthy_count
        }
        # Pass analysis results to the dashboard template
        return analysis_result
    except Exception as e:
        error_message = str(e)
        LOGS['CSV Analysis'].append("Error occurred during analysis: {}".format(error_message))
        return None


@app.route('/', methods=['GET', 'POST'])
def upload_file():
    global VICTIM_FILE
    if request.method == 'POST':
        file = request.files['file']
        if file:
            filename = secure_filename(file.filename)
            file_path = os.path.join(UPLOAD_FOLDER, filename)
            file.save(file_path)
            VICTIM_FILE = file_path
            return redirect(url_for('loading'))
    return render_template('upload.html')


@app.route('/loading')
def loading():
    if VICTIM_FILE is None:
        return render_template('loading.html')
    else:
        return redirect(url_for('analyze_file'))


@app.route('/analyze', methods=['GET', 'POST'])
def analyze_file():
    global VICTIM_FILE
    if VICTIM_FILE is None:
        return render_template('error.html', error='No file uploaded!')
    try:
        LOGS['CSV Analysis'] = []
        LOGS['Windows Artifacts'] = {'pid_processes': [], 'registry_entries': [], 'network_connections': [], 'recycle_bin_entries': []}
        LOGS['Other Analysis'] = []
        fetch_windows_artifacts()
        # Fetch running processes

        monitor_behavior()
        analysis_result = analyze_data()
        if analysis_result:
            # Calculate file size
            file_size = os.path.getsize(VICTIM_FILE)
            analysis_result['file_size'] = file_size
            # Add analysis results to logs
            LOGS['CSV Analysis'].append("Analysis successful.")
            
 
            LOGS['Windows Artifacts']["network_connections"] =  fetch_network_connections()
            LOGS['Windows Artifacts']["recycle_bin_entries"] =  fetch_recycle_bin_entries()
            LOGS['Windows Artifacts']["registry_entries"] =  fetch_registry_entries()

            # Debug: Print the contents of LOGS['Windows Artifacts']
            print("Windows Artifacts pid_processes Data:", len(LOGS['Windows Artifacts']["pid_processes"]),type(LOGS['Windows Artifacts']["pid_processes"]))
            print("Windows Artifacts registry_entries Data:", len(LOGS['Windows Artifacts']["registry_entries"]),type(LOGS['Windows Artifacts']["registry_entries"]),LOGS['Windows Artifacts']["registry_entries"])
            print("Windows Artifacts network_connections Data:", len(LOGS['Windows Artifacts']["network_connections"]),type(LOGS['Windows Artifacts']["network_connections"]))
            print("Windows Artifacts recycle_bin_entries Data:", len(LOGS['Windows Artifacts']["recycle_bin_entries"]),type(LOGS['Windows Artifacts']["recycle_bin_entries"]),LOGS['Windows Artifacts']["recycle_bin_entries"])
            

            return render_template('dashboard.html', analysis_result=analysis_result, csv_logs=LOGS['CSV Analysis'], artefact_logs=LOGS['Windows Artifacts'], other_logs=LOGS['Other Analysis'])
        else:
            return render_template('error.html', error="Error occurred during analysis.")
    except Exception as e:
        error_message = str(e)
        LOGS['CSV Analysis'].append("Error occurred during analysis: {}".format(error_message))
        return render_template('error.html', error=error_message)



if __name__ == '__main__':
    app.run(debug=True)
